{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b4257680",
      "metadata": {},
      "source": [
        "Importing required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9d7c5536",
      "metadata": {
        "id": "9d7c5536",
        "outputId": "6d63335f-5747-4c67-d171-bd0f5a237c6c"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import cv2\n",
        "from mtcnn import MTCNN\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms, models\n",
        "import torch.nn.functional as Func"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "61390cd6",
      "metadata": {},
      "source": [
        "Loading the ready Model - which is a .pt file (PyTorch Model File)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "eeaa4361",
      "metadata": {
        "id": "eeaa4361"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ragha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "state_dict = torch.load('Final_FaceMask_detection_model.pt', map_location=torch.device('cpu'))\n",
        "\n",
        "class FaceMaskModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FaceMaskModel, self).__init__()\n",
        "        self.model = models.resnet50(weights=True)\n",
        "        num_features = self.model.fc.in_features\n",
        "        self.model.fc = nn.Linear(num_features, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "# Face mask detection model\n",
        "model = FaceMaskModel()\n",
        "model.load_state_dict(state_dict)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "# Transformation for input image\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "# labels (with mask and without mask)\n",
        "labels = ['Without Mask', 'With Mask']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "1786d8ce",
      "metadata": {},
      "source": [
        "## Facemask Detection using File Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6da56ad8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Getting the uploaded image file\n",
        "image_path = \"C:/Users/ragha/Desktop/Projects/Face-mask-detection/SampleImages/Sample_without_mask.jpg\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "29f2d0f4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No face mask detected with probability: 0.999928481891402\n"
          ]
        }
      ],
      "source": [
        "class FaceMaskModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FaceMaskModel, self).__init__()\n",
        "        self.model = models.resnet50(weights=True)\n",
        "        num_features = self.model.fc.in_features\n",
        "        self.model.fc = nn.Linear(num_features, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# calling our model\n",
        "model = FaceMaskModel()\n",
        "model_path = \"C:/Users/ragha/Desktop/Projects/Face-mask-detection/Final_FaceMask_detection_model.pt\" \n",
        "model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "# the image transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "# Preprocess the image\n",
        "input_tensor = transform(Image.open(image_path).convert(\"RGB\"))\n",
        "input_batch = input_tensor.unsqueeze(0)  # Add a batch dimension\n",
        "\n",
        "# face mask detection\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    output = model(input_batch)\n",
        "\n",
        "class_probabilities = Func.softmax(output, dim=1)\n",
        "mask_probability = class_probabilities[0, 1].item()\n",
        "\n",
        "threshold = 0.5  # Threshold\n",
        "if mask_probability > threshold:\n",
        "    print(\"Face mask detected with probability:\", mask_probability)\n",
        "else:\n",
        "    print(\"No face mask detected with probability:\", 1 - mask_probability)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "1dc9a151",
      "metadata": {},
      "source": [
        "## Real Time Facemask Detection using Front Camera"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "17b0d3e9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 134ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3/3 [==============================] - 0s 5ms/step\n",
            "1/1 [==============================] - 0s 112ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5/5 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 0s 5ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        }
      ],
      "source": [
        "detector = MTCNN()\n",
        "\n",
        "# Initialize the video capture\n",
        "cap = cv2.VideoCapture(0)\n",
        "if not cap.isOpened():\n",
        "    print(\"Failed to open the camera\")\n",
        "    exit()\n",
        "    \n",
        "    \n",
        "\n",
        "# Loop over frames from the video stream\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        print(\"Failed to capture frame\")\n",
        "        break\n",
        "        \n",
        "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    # face detection using MTCNN\n",
        "    boxes = detector.detect_faces(rgb_frame)\n",
        "\n",
        "    # detected faces\n",
        "    for box in boxes:\n",
        "        x, y, width, height = box['box']\n",
        "\n",
        "        #face region from the frame\n",
        "        face = frame[y:y+height, x:x+width]\n",
        "\n",
        "        #  face to PIL Image format\n",
        "        pil_face = Image.fromarray(cv2.cvtColor(face, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "        transformed_face = transform(pil_face)\n",
        "\n",
        "        # a batch dimension to the face image\n",
        "        transformed_face = transformed_face.unsqueeze(0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(transformed_face)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        label = labels[predicted.item()]\n",
        "\n",
        "        # bounding box and lebel\n",
        "        cv2.rectangle(frame, (x, y), (x+width, y+height), (0, 255, 0), 2)\n",
        "        cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "        \n",
        "    cv2.imshow('Face Mask Detection', frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "   \n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
